{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1VNUB3J+B8Z8eaz2A9fUj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirahhamid/GAN-medical-image-augmentation/blob/main/GAN_PYTORCH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple Implementation of GAN on MRI images using Pytorch**\n",
        "\n",
        "Total of 70 MRI image samples used in this implementation. The data is acquired from Alzheimer's Disease Neuroimaging Initiative (ADNI) database --> (https://adni.loni.usc.edu/)\n",
        "\n",
        "Input data dimension size: 256 x 256 x 3\n",
        "\n",
        "Two main components of GAN: Discriminator (D) and Generator (G)\n",
        "\n",
        "We build the simple convolutional neural networks for both components.\n",
        "Generator: Generate 'fake' image based on random noise (vector numbers)\n",
        "Discriminator: Do binary classification --> 'fake' image: 0, 'real':1\n",
        "\n",
        "**Notes: Set the GPU --> change runtime type**"
      ],
      "metadata": {
        "id": "7s3tX5yp2anM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mount the drive**"
      ],
      "metadata": {
        "id": "Vc5Olnsk41Xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "5qeEyHTQoJkm",
        "outputId": "e6395159-68a1-4331-b602-f965ae5bbce3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import** **the libraries and packages**"
      ],
      "metadata": {
        "id": "4x1Lo5pO4_Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "dNCXhfpP0oUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialization of the parameters and configuration**"
      ],
      "metadata": {
        "id": "lyQelWcy6gH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SEED = 40\n",
        "NOISE_DIM = 100\n",
        "CHANNELS  = 3\n",
        "WIDTH = HEIGHT = 256\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" #use GPU\n",
        "\n",
        "# training parameters\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "STEPS_PER_EPOCH = 2000\n",
        "\n",
        "# MRI data folder\n",
        "MAIN_DIR = \"/content/drive/MyDrive/Colab Notebooks/AD-NEW\"  # change to your path\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "\n",
        "def set_requires_grad(model, flag: bool):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = flag"
      ],
      "metadata": {
        "id": "ctalIRnw02On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualize the generated image**"
      ],
      "metadata": {
        "id": "VPbPjcDl5r9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def sample_images_torch(generator, noise_np, nrow=2, ncol=5, figsize=(22, 8), save=False, save_prefix=\"gen\"):\n",
        "    \"\"\"\n",
        "    noise_np: (N, NOISE_DIM) numpy float32\n",
        "    Generates N images, displays first nrow*ncol.\n",
        "    \"\"\"\n",
        "    generator.eval()\n",
        "    z = torch.from_numpy(noise_np).float().to(DEVICE)        # (N, NOISE_DIM)\n",
        "    fake = generator(z)                                      # (N, 3, 256, 256) in [-1,1]\n",
        "    fake = (fake + 1) / 2                                    # -> [0,1]\n",
        "    fake = fake.clamp(0, 1).cpu()\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(nrow * ncol):\n",
        "        img = fake[i].permute(1, 2, 0).numpy()               # HWC\n",
        "        plt.subplot(nrow, ncol, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        if save:\n",
        "            plt.savefig(f\"{save_prefix}_{i}.png\", dpi=200)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    generator.train()"
      ],
      "metadata": {
        "id": "92I6hspV10kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load the data**"
      ],
      "metadata": {
        "id": "eVPAIR7K50qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(folder):\n",
        "    imgs = []\n",
        "    for fname in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, fname)\n",
        "\n",
        "        # Force grayscale\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        img = cv2.resize(img, (WIDTH, HEIGHT), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # Repeat grayscale to 3 channels\n",
        "        img = np.stack([img, img, img], axis=-1)  # (H, W, 3)\n",
        "\n",
        "        imgs.append(img)\n",
        "\n",
        "    return np.array(imgs, dtype=np.uint8)\n",
        "\n",
        "data = load_images(MAIN_DIR)\n",
        "print(\"Loaded data:\", data.shape)\n",
        "\n",
        "if data.shape[0] < BATCH_SIZE:\n",
        "    raise ValueError(f\"Not enough images ({data.shape[0]}) for batch size {BATCH_SIZE}.\")\n",
        "\n",
        "X_train = data\n",
        "\n",
        "# Normalize to [-1, 1]\n",
        "X_train = (X_train.astype(np.float32) - 127.5) / 127.5  # float32\n",
        "\n",
        "print(\"X_train:\", X_train.shape, X_train.dtype, \"min/max:\", X_train.min(), X_train.max())\n",
        "\n",
        "# Visualize some real images\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(min(10, X_train.shape[0])):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    img = (X_train[i] + 1) / 2\n",
        "    plt.imshow(np.clip(img, 0, 1))\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Move to torch tensor (N,3,256,256)\n",
        "X_train_torch = torch.from_numpy(X_train).float().permute(0, 3, 1, 2)  # NHWC -> NCHW"
      ],
      "metadata": {
        "id": "3cEHbmynKRjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''def load_images(folder):\n",
        "    imgs = []\n",
        "    for fname in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, fname)\n",
        "        try:\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # BGR -> RGB\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # resize to 256x256\n",
        "            img = cv2.resize(img, (WIDTH, HEIGHT), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            imgs.append(img)\n",
        "        except Exception as e:\n",
        "            # print(img_path, e)\n",
        "            continue\n",
        "\n",
        "    imgs = np.array(imgs, dtype=np.uint8)  # (N,256,256,3)\n",
        "    return imgs'''\n",
        "\n"
      ],
      "metadata": {
        "id": "xIzMZdBO2E4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build the Generator and Discriminator Model**"
      ],
      "metadata": {
        "id": "sYg6rocE58Lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    noise (NOISE_DIM,) -> 256x256x3\n",
        "    Start from 32x32 then upsample:\n",
        "    32 -> 64 -> 128 -> 256\n",
        "    \"\"\"\n",
        "    def __init__(self, noise_dim=NOISE_DIM, out_channels=CHANNELS):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 32 * 32 * 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "\n",
        "        self.up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 32->64\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1),  # 64->128\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128,  64, kernel_size=4, stride=2, padding=1),  # 128->256\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.fc(z)                       # (B, 32*32*256)\n",
        "        x = x.view(-1, 256, 32, 32)          # (B, 256, 32, 32)\n",
        "        return self.up(x)                    # (B, 3, 256, 256)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    256x256x3 -> 1 (real/fake)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=CHANNELS):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),   # 256->256\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),           # 256->128\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),          # 128->64\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),          # 64->32\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),          # 32->16\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# ================= BUILD =================\n",
        "generator = Generator().to(DEVICE)\n",
        "discriminator = Discriminator().to(DEVICE)\n",
        "\n",
        "print(generator)\n",
        "print(discriminator)"
      ],
      "metadata": {
        "id": "TIMg0dM32S4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Set the loss function and optimizer**"
      ],
      "metadata": {
        "id": "SqUeG7G_6FNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "D_OPT   = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "GAN_OPT = optim.Adam(generator.parameters(),     lr=2e-4, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "G4bJNC6E2V22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Start Training**"
      ],
      "metadata": {
        "id": "catp5xjP6ORM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    last_d_loss, last_g_loss = None, None\n",
        "\n",
        "    for _ in tqdm(range(STEPS_PER_EPOCH), desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "        # ----- Sample real images\n",
        "        idx = torch.randint(0, X_train_torch.size(0), (BATCH_SIZE,))\n",
        "        real_X = X_train_torch[idx].to(DEVICE)  # (B,3,256,256)\n",
        "\n",
        "        # ----- Generate fake images\n",
        "        z = torch.randn(BATCH_SIZE, NOISE_DIM, device=DEVICE)\n",
        "        fake_X = generator(z)  # (B,3,256,256)\n",
        "\n",
        "        # ----- Train Discriminator (real=1, fake=0)\n",
        "        discriminator.train()\n",
        "        generator.train()\n",
        "        set_requires_grad(discriminator, True)\n",
        "\n",
        "        D_OPT.zero_grad()\n",
        "\n",
        "        real_y = torch.ones(BATCH_SIZE, 1, device=DEVICE)\n",
        "        fake_y = torch.zeros(BATCH_SIZE, 1, device=DEVICE)\n",
        "\n",
        "        pred_real = discriminator(real_X)\n",
        "        loss_real = criterion(pred_real, real_y)\n",
        "\n",
        "        pred_fake = discriminator(fake_X.detach())\n",
        "        loss_fake = criterion(pred_fake, fake_y)\n",
        "\n",
        "        d_loss = 0.5 * (loss_real + loss_fake)\n",
        "        d_loss.backward()\n",
        "        D_OPT.step()\n",
        "\n",
        "        # ----- Train Generator (freeze D): want D(G(z)) = 1\n",
        "        set_requires_grad(discriminator, False)\n",
        "        GAN_OPT.zero_grad()\n",
        "\n",
        "        z2 = torch.randn(BATCH_SIZE, NOISE_DIM, device=DEVICE)\n",
        "        gen_X = generator(z2)\n",
        "        pred = discriminator(gen_X)\n",
        "\n",
        "        g_loss = criterion(pred, real_y)\n",
        "        g_loss.backward()\n",
        "        GAN_OPT.step()\n",
        "\n",
        "        last_d_loss = d_loss.item()\n",
        "        last_g_loss = g_loss.item()\n",
        "\n",
        "    print(f\"EPOCH: {epoch + 1} | Generator Loss: {last_g_loss:.4f} | Discriminator Loss: {last_d_loss:.4f}\")\n",
        "\n",
        "    noise_np = np.random.normal(0, 1, size=(10, NOISE_DIM)).astype(np.float32)\n",
        "    sample_images_torch(generator, noise_np, nrow=2, ncol=5, figsize=(22, 8), save=False)\n",
        "\n",
        "# Final samples\n",
        "noise_np = np.random.normal(0, 1, size=(100, NOISE_DIM)).astype(np.float32)\n",
        "sample_images_torch(generator, noise_np, nrow=10, ncol=10, figsize=(24, 20), save=False)\n"
      ],
      "metadata": {
        "id": "eW1sgm0SitTm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}